{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b4c2a-44ca-4f1c-8327-f6e976ca30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is a parameter?\n",
    "\n",
    "Parameters are the internal variables of a model that are learned from the training data. They are essential for making predictions and are adjusted during the training process to minimize the error or cost function. For example, in a linear regression model, the parameters are the slope (m) and intercept (c) of the line, which are determined by fitting the model to the data\n",
    "1\n",
    ". Similarly, in neural networks, the weights and biases are the parameters that are optimized during training\n",
    "2\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f6328b-0356-44a5-aa6d-bcb2fce66600",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is correlation?\n",
    " What does negative correlation mean?\n",
    "\n",
    "Correlation is a statistical measure that describes the extent to which two variables are related.\n",
    "It quantifies the degree to which changes in one variable are associated with changes in another variable.\n",
    "Variables move in opposite directions. For example, the price of a product and its demand often have a negative correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9094d299-471e-4b20-9c10-56210ebfebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    " Define Machine Learning. What are the main components in Machine Learning?\n",
    "Machine learning is a branch of artificial intelligence that enables algorithms to uncover hidden patterns within datasets. \n",
    "Represenrtaion\n",
    "Evaluation\n",
    "Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b090bcfe-27d6-4551-9615-e778adea32dc",
   "metadata": {},
   "outputs": [],
   "source": [
    " How does loss value help in determining whether the model is good or not?\n",
    "Loss is a value that represents the summation of errors in our model. It measures how well (or bad) our model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2529a4-3dd8-4fae-a970-5e0a233525e0",
   "metadata": {},
   "outputs": [],
   "source": [
    " What are continuous and categorical variables?\n",
    "Continuous variables are quantitative variables that can take any value within a range.\n",
    "They are measured rather than counted and can have an infinite number of possible values between any two points. \n",
    "Categorical variables represent groupings or categories and can be further divided into binary, nominal, and ordinal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24ca1c-b0d7-435d-b436-ed696868c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " How do we handle categorical variables in Machine Learning? What are the common t\n",
    " echniques?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f47a50c-3b75-499b-8ca4-8da67909f637",
   "metadata": {},
   "outputs": [],
   "source": [
    " What do you mean by training and testing a dataset?\n",
    "Testing data is used to determine the performance of the trained model, whereas training data is used to train the machine learning model. \n",
    "You will need unknown information to test your machine learning model after it was created (using your training data). This data is known as testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b50dfe-0505-4e1e-ae2a-a486c9a063e4",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is sklearn.preprocessing?\n",
    "Preprocessing is a crucial step in the machine learning pipeline, as it transforms raw data into a format that is more suitable for modeling. The sklearn.preprocessing module in Scikit-Learn provides several utility functions and transformer classes to facilitate this process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccc7282-07b0-4691-b255-a8fdbb3239d9",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is a Test set?\n",
    "A test set is a crucial component in the field of statistics, data analysis, and data science, serving as a subset of data used to evaluate the performance of a predictive model. In the context of machine learning, the test set is distinct from both the training set and the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c5940f-2a47-4eeb-83ef-c1c99317d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    " 10)How do we split data for model fitting (training and testing) in Python?\n",
    " How do you approach a Machine Learning problem\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9c7379-55a2-4ded-8049-d5ca25aa2089",
   "metadata": {},
   "outputs": [],
   "source": [
    " Why do we have to perform EDA before fitting a model to the data?\n",
    "Before fitting any model, it is often important to conduct an exploratory data analysis (EDA) in order to check assumptions, inspect the data for anomalies (such as missing, duplicated, or mis-coded data), and inform feature selection/transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9484e4f0-7d1d-47c8-8ce0-5c19bc0ebdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is correlation?\n",
    "Correlation is a statistical measure that describes the extent to which two variables are related. It quantifies the degree to which changes in one variable are associated with changes in another variable. Correlation is commonly used in various fields such as economics, finance, and social sciences to identify and measure relationships between variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020cfdf6-648b-4465-ae01-17ddaf1af4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    " What does negative correlation mean?\n",
    " negative correlation means that:\n",
    "Two variables tend to move in opposite directions.\n",
    "5\n",
    "When one variable increases, the other decreases.\n",
    "It is also known as an inverse correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7263e9fc-fbb0-4980-bb07-48bd809f1ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    " How can you find correlation between variables in Python?\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Sample data\n",
    "variable1 = [1, 2, 3, 4, 5]\n",
    "variable2 = [2, 4, 6, 8, 10]\n",
    "\n",
    "# Calculate Pearson correlation coefficient\n",
    "correlation_coefficient, p_value = pearsonr(variable1, variable2)\n",
    "print(f'Correlation Coefficient: {correlation_coefficient}, P-value: {p_value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90e9064-6244-4c5e-80ec-1a8bb5d0b250",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is causation? Explain difference between correlation and causation with an example.\n",
    "Correlation means there is a statistical association between variables. Causation means that a change in one variable causes a change in another variable. In research, you might have come across the phrase “correlation doesn’t imply causation.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f440d627-3135-4dcb-aa0c-fa36226ad655",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
    "Optimizers are algorithms that adjust the parameters of a neural network to minimize the loss function, thereby improving the model’s performance. This blog post will delve into various types of optimizers, their mechanisms, advantages, and practical examples. Key Takeaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098bde90-de17-4edd-bef9-115c60065822",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is sklearn.linear_model ?\n",
    "The linear_model module in Scikit-learn provides various linear models for regression and classification tasks. These models are designed to predict target values as a linear combination of input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d20638-fc42-4999-a0d3-60b529b42acc",
   "metadata": {},
   "outputs": [],
   "source": [
    " What does model.fit() do? What arguments must be given?\n",
    "The fit() method in Scikit-Learn is used to train a machine learning model. Training a model involves feeding it with data so it can learn the underlying patterns. This method adjusts the parameters of the model based on the provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289542d1-89be-43fb-948e-2dbc087c009d",
   "metadata": {},
   "outputs": [],
   "source": [
    " What does model.predict() do? What arguments must be given?\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc9d0b-9ba4-429f-8065-0047d5dd3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    " What are continuous and categorical variables?\n",
    "Continuous variables are quantitative variables that can take any value within a range. They are measured rather than counted and can have an infinite number of possible values between any two points. Examples include height, weight, temperature, and time\n",
    "\n",
    ". Continuous variables are often visualized using histograms, box plots, or scatter plots and are analyzed using methods such as mean, median, normal distributions, and regression analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636eaee-b61c-4285-bebd-a6581bc57ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is feature scaling? How does it help in Machine Learning?\n",
    "Scaling is a crucial preprocessing step in machine learning that transforms feature values to a similar scale, \n",
    "ensuring all features contribute equally to the model. This process is essential for datasets with features of varying ranges, units, or magnitudes.\n",
    "Common techniques include standardization, normalization, and min-max scaling. These techniques improve model performance, convergence, and prevent bias from features with larger values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eba1a0-934e-4aaf-b556-797298377ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    " How do we perform scaling in Python?\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Example data\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(scaled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016fb54-0586-4f1d-92b6-8719f7612a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    " What is sklearn.preprocessing?\n",
    "Preprocessing is a crucial step in the machine learning pipeline, as it transforms raw data into a format that is more suitable for modeling.\n",
    "The sklearn.preprocessing module in Scikit-Learn provides several utility functions and transformer classes to facilitate this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c3fb9d-aa48-4b08-aac4-d64017616f39",
   "metadata": {},
   "outputs": [],
   "source": [
    " How do we split data for model fitting (training and testing) in Python?\n",
    "# import modules\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# read the dataset\n",
    "df = pd.read_csv('Real estate.csv')\n",
    "\n",
    "# get the locations\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "\tX, y, test_size=0.05, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6029f13b-a846-484e-ac6d-bcfb06df8293",
   "metadata": {},
   "outputs": [],
   "source": [
    " Explain data encoding?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
